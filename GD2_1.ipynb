{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-reference",
   "metadata": {},
   "source": [
    "# GD 2\n",
    "\n",
    "> 1. ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?\n",
    "\t블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.\n",
    "\n",
    "> 2. 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?\n",
    "\tcats_vs_dogs 데이터셋으로 학습시 몇 epoch동안 안정적으로 loss 감소가 진행 확인되었다.\n",
    "\n",
    "> 3. Ablation Study 결과가 바른 포맷으로 제출되었는가?\n",
    "\tResNet-34, ResNet-50 각각 plain모델과 residual모델을 동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "human-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.applications import imagenet_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "elder-italy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 GoGo!!\n"
     ]
    }
   ],
   "source": [
    "# 추가로 import해야 할 패키지들을 먼저 가져옵니다. \n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import models\n",
    "\n",
    "# block 안에 반복적으로 활용되는 L2 regularizer를 선언해 줍니다.\n",
    "def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):\n",
    "  return regularizers.l2(l2_weight_decay) if use_l2_regularizer else None\n",
    "\n",
    "print('Resnet50 GoGo!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CIFAR100 데이터셋을 가져옵시다. \n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "print(\"x_train:\", len(x_train), \"x_test:\", len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "furnished-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               use_l2_regularizer=True,\n",
    "               batch_norm_decay=0.9,\n",
    "               batch_norm_epsilon=1e-5):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    Note that from stage 3,\n",
    "    the second conv layer at main path is with strides=(2, 2)\n",
    "    And the shortcut should have strides=(2, 2) as well\n",
    "    Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    strides: Strides for the second conv layer in the block.\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "    Returns:\n",
    "    Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    shortcut = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      strides=strides,\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '1')(\n",
    "          input_tensor)\n",
    "    shortcut = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '1')(\n",
    "          shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "south-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   use_l2_regularizer=True,\n",
    "                   batch_norm_decay=0.9,\n",
    "                   batch_norm_epsilon=1e-5):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "    Returns:\n",
    "    Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "    x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "invisible-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(num_classes,\n",
    "             batch_size=None,\n",
    "             use_l2_regularizer=True,\n",
    "             rescale_inputs=False,\n",
    "             batch_norm_decay=0.9,\n",
    "             batch_norm_epsilon=1e-5):\n",
    "    \"\"\"Instantiates the ResNet50 architecture.\n",
    "    Args:\n",
    "    num_classes: `int` number of classes for image classification.\n",
    "    batch_size: Size of the batches for each step.\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv/Dense layer.\n",
    "    rescale_inputs: whether to rescale inputs from 0 to 1.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "    Returns:\n",
    "      A Keras model instance.\n",
    "    \"\"\"\n",
    "\n",
    "    input_shape = (32, 32, 3)  # CIFAR100을 위한 input_shape 조정입니다. \n",
    "    img_input = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "    if rescale_inputs:\n",
    "    # Hub image modules expect inputs in the range [0, 1]. This rescales these\n",
    "    # inputs to the range expected by the trained model.\n",
    "      x = layers.Lambda(\n",
    "          lambda x: x * 255.0 - backend.constant(\n",
    "              imagenet_preprocessing.CHANNEL_MEANS,\n",
    "              shape=[1, 1, 3],\n",
    "              dtype=x.dtype),\n",
    "          name='rescale')(\n",
    "              img_input)\n",
    "    else:\n",
    "        x = img_input\n",
    "\n",
    "    if backend.image_data_format() == 'channels_first':\n",
    "        x = layers.Permute((3, 1, 2))(x)\n",
    "        bn_axis = 1\n",
    "    else:  # channels_last\n",
    "        bn_axis = 3\n",
    "\n",
    "    block_config = dict(\n",
    "      use_l2_regularizer=use_l2_regularizer,\n",
    "      batch_norm_decay=batch_norm_decay,\n",
    "      batch_norm_epsilon=batch_norm_epsilon)\n",
    "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "    x = layers.Conv2D(\n",
    "        64, (7, 7),\n",
    "        strides=(2, 2),\n",
    "        padding='valid',\n",
    "        use_bias=False,\n",
    "        kernel_initializer='he_normal',\n",
    "        kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "        name='conv1')(\n",
    "            x)\n",
    "    x = layers.BatchNormalization(\n",
    "        axis=bn_axis,\n",
    "        momentum=batch_norm_decay,\n",
    "        epsilon=batch_norm_epsilon,\n",
    "        name='bn_conv1')(\n",
    "            x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    x = conv_block(\n",
    "        x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), **block_config)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', **block_config)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', **block_config)\n",
    "\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', **block_config)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', **block_config)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', **block_config)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', **block_config)\n",
    "\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', **block_config)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', **block_config)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', **block_config)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', **block_config)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', **block_config)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', **block_config)\n",
    "\n",
    "    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', **block_config)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', **block_config)\n",
    "    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', **block_config)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(\n",
    "        num_classes,\n",
    "        kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "        kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "        bias_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "        name='fc1000')(\n",
    "            x)\n",
    "\n",
    "    # A softmax that is followed by the model loss must be done cannot be done\n",
    "    # in float16 due to numeric issues. So we pass dtype=float32.\n",
    "    x = layers.Activation('softmax', dtype='float32')(x)\n",
    "\n",
    "    # Create model.\n",
    "    return models.Model(img_input, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "developing-hello",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 64)   9408        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 8, 8, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4096        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16384       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 256)    0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16384       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16384       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 8, 8, 128)    32768       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 8, 8, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 8, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131072      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 4, 512)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65536       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147456      activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    65536       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    131072      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   524288      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262144      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    589824      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   262144      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524288      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2097152     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1048576     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1048576     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359296     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1048576     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 100)          204900      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100)          0           fc1000[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,766,052\n",
      "Trainable params: 23,712,932\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(num_classes=100)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "organic-exclusion",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7c0f760499ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 1 Epoch만 학습합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 모델 학습!! \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1)    # 1 Epoch만 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fifth-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet50 GoGo!!\n"
     ]
    }
   ],
   "source": [
    "# 추가로 import해야 할 패키지들을 먼저 가져옵니다. \n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.python.keras import initializers\n",
    "from tensorflow.python.keras import models\n",
    "\n",
    "# block 안에 반복적으로 활용되는 L2 regularizer를 선언해 줍니다.\n",
    "def _gen_l2_regularizer(use_l2_regularizer=True, l2_weight_decay=1e-4):\n",
    "  return regularizers.l2(l2_weight_decay) if use_l2_regularizer else None\n",
    "\n",
    "print('Resnet34 GoGo!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "provincial-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               use_l2_regularizer=True,\n",
    "               batch_norm_decay=0.9,\n",
    "               batch_norm_epsilon=1e-5):\n",
    "  \"\"\"A block that has a conv layer at shortcut.\n",
    "  Note that from stage 3,\n",
    "  the second conv layer at main path is with strides=(2, 2)\n",
    "  And the shortcut should have strides=(2, 2) as well\n",
    "  Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    strides: Strides for the second conv layer in the block.\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "  filters1, filters2, filters3 = filters\n",
    "  if backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "  shortcut = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      strides=strides,\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '1')(\n",
    "          input_tensor)\n",
    "  shortcut = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '1')(\n",
    "          shortcut)\n",
    "\n",
    "  x = layers.add([x, shortcut])\n",
    "  x = layers.Activation('relu')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "future-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   use_l2_regularizer=True,\n",
    "                   batch_norm_decay=0.9,\n",
    "                   batch_norm_epsilon=1e-5):\n",
    "  \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "  Args:\n",
    "    input_tensor: input tensor\n",
    "    kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "    filters: list of integers, the filters of 3 conv layer at main path\n",
    "    stage: integer, current stage label, used for generating layer names\n",
    "    block: 'a','b'..., current block label, used for generating layer names\n",
    "    use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n",
    "    batch_norm_decay: Moment of batch norm layers.\n",
    "    batch_norm_epsilon: Epsilon of batch borm layers.\n",
    "  Returns:\n",
    "    Output tensor for the block.\n",
    "  \"\"\"\n",
    "  filters1, filters2, filters3 = filters\n",
    "  if backend.image_data_format() == 'channels_last':\n",
    "    bn_axis = 3\n",
    "  else:\n",
    "    bn_axis = 1\n",
    "  conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "  bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters1, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2a')(\n",
    "          input_tensor)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2a')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters2,\n",
    "      kernel_size,\n",
    "      padding='same',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2b')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "\n",
    "  x = layers.Conv2D(\n",
    "      filters3, (1, 1),\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name=conv_name_base + '2c')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name=bn_name_base + '2c')(\n",
    "          x)\n",
    "\n",
    "  x = layers.add([x, input_tensor])\n",
    "  x = layers.Activation('relu')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effective-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet34(num_classes,\n",
    "             batch_size=None,\n",
    "             use_l2_regularizer=True,\n",
    "             rescale_inputs=False,\n",
    "             batch_norm_decay=0.9,\n",
    "             batch_norm_epsilon=1e-5):\n",
    "    \n",
    "  input_shape = (32, 32, 3)  # CIFAR100을 위한 input_shape 조정입니다. \n",
    "  img_input = layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "  if rescale_inputs:\n",
    "    # Hub image modules expect inputs in the range [0, 1]. This rescales these\n",
    "    # inputs to the range expected by the trained model.\n",
    "    x = layers.Lambda(\n",
    "        lambda x: x * 255.0 - backend.constant(\n",
    "            imagenet_preprocessing.CHANNEL_MEANS,\n",
    "            shape=[1, 1, 3],\n",
    "            dtype=x.dtype),\n",
    "        name='rescale')(\n",
    "            img_input)\n",
    "  else:\n",
    "    x = img_input\n",
    "\n",
    "  if backend.image_data_format() == 'channels_first':\n",
    "    x = layers.Permute((3, 1, 2))(x)\n",
    "    bn_axis = 1\n",
    "  else:  # channels_last\n",
    "    bn_axis = 3\n",
    "\n",
    "  block_config = dict(\n",
    "      use_l2_regularizer=use_l2_regularizer,\n",
    "      batch_norm_decay=batch_norm_decay,\n",
    "      batch_norm_epsilon=batch_norm_epsilon)\n",
    "  x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)\n",
    "  x = layers.Conv2D(\n",
    "      64, (7, 7),\n",
    "      strides=(2, 2),\n",
    "      padding='valid',\n",
    "      use_bias=False,\n",
    "      kernel_initializer='he_normal',\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='conv1')(\n",
    "          x)\n",
    "  x = layers.BatchNormalization(\n",
    "      axis=bn_axis,\n",
    "      momentum=batch_norm_decay,\n",
    "      epsilon=batch_norm_epsilon,\n",
    "      name='bn_conv1')(\n",
    "          x)\n",
    "  x = layers.Activation('relu')(x)\n",
    "  x = layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "  x = conv_block(\n",
    "      x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), **block_config)\n",
    "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', **block_config)\n",
    "  x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', **block_config)\n",
    "  x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', **block_config)\n",
    "\n",
    "  x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a', **block_config)\n",
    "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b', **block_config)\n",
    "  x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c', **block_config)\n",
    "\n",
    "  x = layers.GlobalAveragePooling2D()(x)\n",
    "  x = layers.Dense(\n",
    "      num_classes,\n",
    "      kernel_initializer=initializers.RandomNormal(stddev=0.01),\n",
    "      kernel_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      bias_regularizer=_gen_l2_regularizer(use_l2_regularizer),\n",
    "      name='fc1000')(\n",
    "          x)\n",
    "\n",
    "  # A softmax that is followed by the model loss must be done cannot be done\n",
    "  # in float16 due to numeric issues. So we pass dtype=float32.\n",
    "  x = layers.Activation('softmax', dtype='float32')(x)\n",
    "\n",
    "  # Create model.\n",
    "  return models.Model(img_input, x, name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sapphire-mouth",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c3efdf81c935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3becadd7652d>\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(num_classes, batch_size, use_l2_regularizer, rescale_inputs, batch_norm_decay, batch_norm_epsilon)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# CIFAR100을 위한 input_shape 조정입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mrescale_inputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Hub image modules expect inputs in the range [0, 1]. This rescales these\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "model = resnet50(num_classes=100)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "inclusive-automation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net34_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_28 (ZeroPaddi multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_509 (Conv2D)          multiple                  832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_509 (Bat multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu_545 (ReLU)             multiple                  0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPaddi multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_47 (Sequential)   (1, 10, 10, 64)           129216    \n",
      "_________________________________________________________________\n",
      "sequential_48 (Sequential)   (1, 5, 5, 128)            661120    \n",
      "_________________________________________________________________\n",
      "sequential_49 (Sequential)   (1, 3, 3, 256)            3948800   \n",
      "_________________________________________________________________\n",
      "sequential_50 (Sequential)   (1, 2, 2, 512)            7882240   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  513000    \n",
      "=================================================================\n",
      "Total params: 13,135,464\n",
      "Trainable params: 13,118,312\n",
      "Non-trainable params: 17,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "class conv_block(tf.keras.Model):\n",
    "    def __init__(self, filters, strides=(2, 2)):\n",
    "        super(conv_block, self).__init__()\n",
    "\n",
    "        self.filters1, self.filters2 = filters\n",
    "        self.strides = strides\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=strides)\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "        self.shortcut_conv = tf.keras.layers.Conv2D(self.filters2, (1, 1), strides=strides)\n",
    "        self.shortcut_bn = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.add_relu = tf.keras.layers.ReLU()\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        shortcut = self.shortcut_conv(input_tensor)\n",
    "        shortcut = self.shortcut_bn(shortcut)\n",
    "\n",
    "        x = self.add([x, shortcut])\n",
    "        x = self.add_relu(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class identity_block(tf.keras.Model):\n",
    "    def __init__(self, filters):\n",
    "        super(identity_block, self).__init__()\n",
    "\n",
    "        self.filters1, self.filters2 = filters\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(self.filters1, (1, 1), strides=(1, 1))\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu1 = tf.keras.layers.ReLU()\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(self.filters2, (3, 3), strides=(1, 1), padding='same')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu2 = tf.keras.layers.ReLU()\n",
    "\n",
    "     \n",
    "        \n",
    "        self.add = tf.keras.layers.Add()\n",
    "        self.add_relu = tf.keras.layers.ReLU()\n",
    "\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.add([x, input_tensor])\n",
    "        x = self.add_relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class ResNet34(tf.keras.Model):\n",
    "    def __init__(self, nb_classes):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "        self.nb_classes = nb_classes\n",
    "\n",
    "        # Stage 1 (Conv1 Layer)\n",
    "        self.zero_padd_1_1 = tf.keras.layers.ZeroPadding2D(padding=(3, 3))\n",
    "        self.conv_1 = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2))\n",
    "        self.bn_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu_1 = tf.keras.layers.ReLU()\n",
    "        self.zero_padd_1_2 = tf.keras.layers.ZeroPadding2D(padding=(1, 1))\n",
    "        self.max_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        # Stage 2\n",
    "        self.stage2 = tf.keras.Sequential()\n",
    "        self.stage2.add(conv_block([64, 64], strides=(1, 1)))\n",
    "        self.stage2.add(identity_block([64, 64]))\n",
    "        self.stage2.add(identity_block([64, 64]))\n",
    "\n",
    "        # Stage 3\n",
    "        self.stage3 = tf.keras.Sequential()\n",
    "        self.stage3.add(conv_block([128, 128]))\n",
    "        self.stage3.add(identity_block([128, 128]))\n",
    "        self.stage3.add(identity_block([128, 128]))\n",
    "        self.stage3.add(identity_block([128, 128]))\n",
    "\n",
    "        # Stage 4\n",
    "        self.stage4 = tf.keras.Sequential()\n",
    "        self.stage4.add(conv_block([256, 256]))\n",
    "        self.stage4.add(identity_block([256, 256]))\n",
    "        self.stage4.add(identity_block([256, 256]))\n",
    "        self.stage4.add(identity_block([256, 256]))\n",
    "        self.stage4.add(identity_block([256, 256]))\n",
    "        self.stage4.add(identity_block([256, 256]))\n",
    "\n",
    "        # Stage 5\n",
    "        self.stage5 = tf.keras.Sequential()\n",
    "        self.stage5.add(conv_block([512, 512]))\n",
    "        self.stage5.add(identity_block([512, 512]))\n",
    "        self.stage5.add(identity_block([512, 512]))\n",
    "\n",
    "\n",
    "        self.gap = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.dense = tf.keras.layers.Dense(self.nb_classes, activation='softmax')\n",
    "\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.zero_padd_1_1(input_tensor)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.zero_padd_1_2(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "\n",
    "        x = self.gap(x)\n",
    "        x = self.dense(x)\n",
    "\n",
    "        return x \n",
    "\n",
    "\n",
    "model = ResNet34(1000)\n",
    "model.build((1, 32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-toddler",
   "metadata": {},
   "source": [
    "## 최종적 모델!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beautiful-density",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "wrong-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building ResNet Block\n",
    "\n",
    "def build_resnet_block(input_layer,\n",
    "                    num_cnn=3, \n",
    "                    channel=64,\n",
    "                    block_num=0,\n",
    "                    is_50=False,\n",
    "                    CHECK_CHANNEL=64,\n",
    "                       plain=False,\n",
    "                   ):\n",
    "#     print(f'입력받은 shape : {input_layer.shape}')\n",
    "\n",
    "    flag = CHECK_CHANNEL == channel\n",
    "    bn = 1\n",
    "    # 입력 레이어\n",
    "    x = input_layer\n",
    "    \n",
    "    # 들어오는 input을 init_identity에 저장시켜 놓는다.\n",
    "    # 이전 블럭에서 들어오는 정보는 init_identity에서 저장\n",
    "    init_identity=x\n",
    "\n",
    "    if not is_50:\n",
    "        # CNN 레이어\n",
    "        # 블럭 내부 구성\n",
    "        for cnn_num in range(num_cnn):\n",
    "            \n",
    "            # 블럭의 첫번째 conv층 쌓기\n",
    "            # 채널이 바뀌면서 이미지의 가로세로 길이가 반으로 줄어야 한다.\n",
    "            # 채널.......으로 분기문을 주면...\n",
    "            # 블럭안에서 Shortcut Connection으로 사용할 identity는 여기서 저장\n",
    "            identity = x\n",
    "            \n",
    "            # flag가 False이면 새로운 Conv Block 쌓는다.\n",
    "            # 그러므로 strides=(2,2)를 사용해서 입력이미지의 사이즈를 줄인다.\n",
    "            if flag :\n",
    "                # 첫번째 Conv\n",
    "                x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(3,3),\n",
    "                    kernel_initializer='he_normal',\n",
    "                    padding='same',\n",
    "                    name=f'stage{block_num+2}_{cnn_num+1}_conv1'\n",
    "                )(x)    \n",
    "                \n",
    "            else :\n",
    "                x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(3,3),\n",
    "                    kernel_initializer='he_normal',\n",
    "                    padding='same',\n",
    "                    strides=(2,2),\n",
    "                    name=f'stage{block_num+2}_{cnn_num+1}_conv1'\n",
    "                )(x)\n",
    "                \n",
    "            x = keras.layers.BatchNormalization(\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_bn{bn}'\n",
    "            )(x)\n",
    "            bn += 1\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            ######\n",
    "            # 두번째 conv 층 (블럭의 conv 마지막 레이어)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(3,3),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_conv2'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization(\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_bn{bn}'\n",
    "            )(x)\n",
    "            bn += 1\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            ###########################\n",
    "            \n",
    "            # plain을 True로 주면 아래 shortcut connection을 만들지 않게된다.\n",
    "            if not plain :\n",
    "                \n",
    "                # identity block\n",
    "                # 채널이 바뀔 때 => identity block에서 strides를 2로 주면서\n",
    "                # 그때 identity의 가로세로 사이즈를 줄여야한다\n",
    "                # 맨 처음 입력이 될때는 어떻게 할 것인가? => 기존에 default 값을 64로 주어서 Flag를 True로 유지\n",
    "                if flag :\n",
    "                    init_identity = keras.layers.Conv2D(\n",
    "                        filters=channel,\n",
    "                        kernel_size=(1,1),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_short'\n",
    "                    )(init_identity)\n",
    "\n",
    "                else :\n",
    "                    init_identity = keras.layers.Conv2D(\n",
    "                        filters=channel,\n",
    "                        kernel_size=(1,1),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        strides=(2,2),\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_short'\n",
    "                    )(init_identity)\n",
    "\n",
    "                init_identity = keras.layers.BatchNormalization(\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_bn4'\n",
    "                )(init_identity)\n",
    "\n",
    "                flag=True\n",
    "\n",
    "                # AD\n",
    "                if cnn_num == 0:\n",
    "                    x = keras.layers.Add(\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_add'\n",
    "                    )([x, init_identity])\n",
    "                    x = keras.layers.Activation('relu')(x)\n",
    "                else :\n",
    "                    x = keras.layers.Add(\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_add'\n",
    "                    )([x, identity])\n",
    "                    x = keras.layers.Activation('relu')(x)\n",
    "#################################################################### \n",
    "    # is_50 = Flase\n",
    "    else:\n",
    "\n",
    "        for cnn_num in range(num_cnn):\n",
    "            \n",
    "            # 블럭의 첫번째 conv층 쌓기\n",
    "            identity = x\n",
    "            \n",
    "            if flag :\n",
    "                 x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(1,1),\n",
    "                    kernel_initializer='he_normal',\n",
    "                    padding='same',\n",
    "                    name=f'stage{block_num+2}_{cnn_num+1}_conv1'\n",
    "                )(x)    \n",
    "                \n",
    "            else :\n",
    "                x = keras.layers.Conv2D(\n",
    "                    filters=channel,\n",
    "                    kernel_size=(1,1),\n",
    "                    kernel_initializer='he_normal',\n",
    "                    padding='same',\n",
    "                    strides=(2,2),\n",
    "                    name=f'stage{block_num+2}_{cnn_num+1}_conv1'\n",
    "                )(x)\n",
    "                \n",
    "\n",
    "            x = keras.layers.BatchNormalization(\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_bn{bn}'\n",
    "            )(x)\n",
    "            bn+=1\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            ######\n",
    "            # 두번째 conv 층 (블럭의 conv 마지막 레이어)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel,\n",
    "                kernel_size=(3,3),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_conv2',\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization(\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_bn{bn}'\n",
    "            )(x)\n",
    "            bn+=1\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            ### 3번째 Conv (앞에 채널의 4배)\n",
    "            x = keras.layers.Conv2D(\n",
    "                filters=channel*4,\n",
    "                kernel_size=(1,1),\n",
    "                kernel_initializer='he_normal',\n",
    "                padding='same',\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_conv3'\n",
    "            )(x)\n",
    "            x = keras.layers.BatchNormalization(\n",
    "                name=f'stage{block_num+2}_{cnn_num+1}_bn{bn}'\n",
    "            )(x)\n",
    "            bn+=1\n",
    "            x = keras.layers.Activation('relu')(x)\n",
    "            \n",
    "            ###########################\n",
    "            \n",
    "            # identity block\n",
    "            # 채널이 바뀔 때 => identity block에서 strides를 2로 주면서\n",
    "            # 그때 identity의 가로세로 사이즈를 줄여야한다\n",
    "            # 맨 처음 입력이 될때는 어떻게 할 것인가? => 기존에 default 값을 64로 주면 될듯\n",
    "            \n",
    "            if not plain :\n",
    "                \n",
    "                if flag :\n",
    "                    init_identity = keras.layers.Conv2D(\n",
    "                        filters=channel*4,\n",
    "                        kernel_size=(1,1),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_short'\n",
    "                    )(init_identity)\n",
    "\n",
    "                else :\n",
    "                    init_identity = keras.layers.Conv2D(\n",
    "                        filters=channel*4,\n",
    "                        kernel_size=(1,1),\n",
    "                        kernel_initializer='he_normal',\n",
    "                        padding='same',\n",
    "                        strides=(2,2),\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_short'\n",
    "                    )(init_identity)\n",
    "\n",
    "                init_identity = keras.layers.BatchNormalization(\n",
    "                    name=f'stage{block_num+2}_{cnn_num+1}_bn4'\n",
    "                )(init_identity)\n",
    "\n",
    "                flag=True\n",
    "\n",
    "\n",
    "                # AD\n",
    "                # 블럭의 첫번째 shortcut connection에서는 init_identity를 사용\n",
    "                # 이후 shortcut connection에서는 블럭 내에서 생기는 identity를 사용\n",
    "                if cnn_num == 0:\n",
    "                    x = keras.layers.Add(\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_add'\n",
    "                    )([x, init_identity])\n",
    "                    x = keras.layers.Activation('relu')(x)\n",
    "                else :\n",
    "                    x = keras.layers.Add(\n",
    "                        name=f'stage{block_num+2}_{cnn_num+1}_add'\n",
    "                    )([x, identity])\n",
    "                    x = keras.layers.Activation('relu')(x)\n",
    "#################################################################### \n",
    "\n",
    "    return x, CHECK_CHANNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-circus",
   "metadata": {},
   "source": [
    "## ResNet-34 : 블럭 생성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aware-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_input_layer = keras.layers.Input(shape=(32,32,3))   # 입력 레이어 생성\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(7,7),\n",
    "        padding='same',\n",
    "        strides=2,\n",
    "        kernel_initializer='he_normal',\n",
    "    )(resnet_input_layer)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2), \n",
    "    strides=2\n",
    ")(x)\n",
    "\n",
    "resnet_block_output, CHECK_CHANNEL = build_resnet_block(x, \n",
    "                                                        channel=64, \n",
    "                                                        num_cnn=3, \n",
    "                                                        block_num=0)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=128,\n",
    "#                                          num_cnn = 4,\n",
    "#                                          block_num=1,CHECK_CHANNEL=CHECK_CHANNEL)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=256,\n",
    "#                                          num_cnn = 6,\n",
    "#                                          block_num=2,CHECK_CHANNEL=CHECK_CHANNEL)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=512,\n",
    "#                                          num_cnn = 3,\n",
    "#                                          block_num=3,CHECK_CHANNEL=CHECK_CHANNEL)\n",
    "\n",
    "resnet_block_output = keras.layers.AveragePooling2D(pool_size=(1,1))(resnet_block_output)\n",
    "resnet_block_output = keras.layers.Flatten(name='flatten')(resnet_block_output)\n",
    "resnet_block_output = keras.layers.Dense(10, activation='softmax', name='predictions')(resnet_block_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "controversial-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_546 (Conv2D)             (None, 16, 16, 64)   9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_546 (BatchN (None, 16, 16, 64)   256         conv2d_546[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16, 16, 64)   0           batch_normalization_546[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)         (None, 8, 8, 64)     36928       max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 8, 8, 64)     0           stage2_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_short (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 8, 64)     0           stage2_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_add (Add)              (None, 8, 8, 64)     0           activation_2[0][0]               \n",
      "                                                                 stage2_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 64)     0           stage2_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)         (None, 8, 8, 64)     36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn3 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 8, 8, 64)     0           stage2_2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 8, 8, 64)     0           stage2_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_add (Add)              (None, 8, 8, 64)     0           activation_5[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 8, 64)     0           stage2_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)         (None, 8, 8, 64)     36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn5 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8, 8, 64)     0           stage2_3_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn6 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 64)     0           stage2_3_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_add (Add)              (None, 8, 8, 64)     0           activation_8[0][0]               \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 8, 64)     0           stage2_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 8, 8, 64)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 4096)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           40970       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 278,218\n",
      "Trainable params: 277,194\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-distribution",
   "metadata": {},
   "source": [
    "## ResNet-50 : 블럭 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "brutal-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_input_layer = keras.layers.Input(shape=(32,32,3))   # 입력 레이어 생성\n",
    "\n",
    "x = keras.layers.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(7,7),\n",
    "        padding='same',\n",
    "        strides=2,\n",
    "        kernel_initializer='he_normal',\n",
    "    )(resnet_input_layer)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Activation('relu')(x)\n",
    "x = keras.layers.MaxPooling2D(\n",
    "    pool_size=(2,2), \n",
    "    strides=2\n",
    ")(x)\n",
    "\n",
    "resnet_block_output, CHECK_CHANNEL = build_resnet_block(x, \n",
    "                                                        channel=64, \n",
    "                                                        num_cnn=3, \n",
    "                                                        block_num=0,\n",
    "                                                       is_50=True)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=128,\n",
    "#                                          num_cnn = 4,\n",
    "#                                          block_num=1,CHECK_CHANNEL=CHECK_CHANNEL,\n",
    "#                                                        is_50=True)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=256,\n",
    "#                                          num_cnn = 6,\n",
    "#                                          block_num=2,CHECK_CHANNEL=CHECK_CHANNEL,\n",
    "#                                                        is_50=True)\n",
    "\n",
    "# resnet_block_output, CHECK_CHANNEL = build_resnet_block(resnet_block_output,\n",
    "#                                          channel=512,\n",
    "#                                          num_cnn = 3,\n",
    "#                                          block_num=3,CHECK_CHANNEL=CHECK_CHANNEL,\n",
    "#                                                        is_50=True)\n",
    "\n",
    "resnet_block_output = keras.layers.AveragePooling2D(pool_size=(1,1))(resnet_block_output)\n",
    "resnet_block_output = keras.layers.Flatten(name='flatten')(resnet_block_output)\n",
    "resnet_block_output = keras.layers.Dense(10, activation='softmax', name='predictions')(resnet_block_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ancient-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_547 (Conv2D)             (None, 16, 16, 64)   9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_547 (BatchN (None, 16, 16, 64)   256         conv2d_547[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 64)   0           batch_normalization_547[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling2D) (None, 8, 8, 64)     0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn3 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_short (Conv2D)         (None, 8, 8, 256)    16640       max_pooling2d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 256)    0           stage2_1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn4 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_add (Add)              (None, 8, 8, 256)    0           activation_13[0][0]              \n",
      "                                                                 stage2_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 256)    0           stage2_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)         (None, 8, 8, 64)     16448       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn5 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn6 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 256)    0           stage2_2_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_add (Add)              (None, 8, 8, 256)    0           activation_17[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 256)    0           stage2_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)         (None, 8, 8, 64)     16448       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn7 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn8 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn9 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 256)    0           stage2_3_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_add (Add)              (None, 8, 8, 256)    0           activation_21[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 256)    0           stage2_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 256)    0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16384)        0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           163850      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 393,610\n",
      "Trainable params: 390,666\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 블록 1개짜리 model 생성\n",
    "model = keras.Model(inputs=resnet_input_layer, outputs=resnet_block_output)  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "subjective-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-deviation",
   "metadata": {},
   "source": [
    "# ResNet Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aggressive-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 모델 자체를 생성하는 함수입니다.\n",
    "def build_resnet(input_shape=(32,32,3),\n",
    "              num_cnn_list=[3, 4, 6, 3],\n",
    "              channel_list=[64,128,256,512],\n",
    "              num_classes=10,\n",
    "                is_50=False,\n",
    "                plain=False,):\n",
    "    \n",
    "    assert len(num_cnn_list) == len(channel_list) #모델을 만들기 전에 config list들이 같은 길이인지 확인합니다.\n",
    "    \n",
    "    input_layer = keras.layers.Input(shape=input_shape, name=\"input_layer\")  # input layer를 만들어둡니다.\n",
    "    output = input_layer # 뒤에서 사용하는 인자와 통일해주기 위해서 'output'이라고 한다\n",
    "    \n",
    "    output = keras.layers.Conv2D(\n",
    "        filters=channel_list[0],\n",
    "        kernel_size=(7,7),\n",
    "        padding='same',\n",
    "        strides=2,\n",
    "        kernel_initializer='he_normal',\n",
    "    )(output)\n",
    "    output = keras.layers.BatchNormalization()(output)\n",
    "    output = keras.layers.Activation('relu')(output)\n",
    "    output = keras.layers.MaxPooling2D(\n",
    "        pool_size=(2,2), \n",
    "        strides=2,\n",
    "        name='stage2_0_maxpooling'\n",
    "    )(output)\n",
    "    \n",
    "    cc = 64\n",
    "    \n",
    "    # config list들의 길이만큼 반복해서 블록을 생성합니다.\n",
    "    for i, (num_cnn, channel) in enumerate(zip(num_cnn_list, channel_list)):\n",
    "        output, cc = build_resnet_block(\n",
    "            output,\n",
    "            num_cnn=num_cnn, \n",
    "            channel=channel,\n",
    "            block_num=i,\n",
    "            is_50=is_50,\n",
    "            CHECK_CHANNEL=cc,\n",
    "            plain=plain\n",
    "        )\n",
    "        \n",
    "    output = keras.layers.AveragePooling2D(pool_size=(1,1), name='avg_pool')(output)\n",
    "    output = keras.layers.Flatten(name='flatten')(output)\n",
    "    output = keras.layers.Dense(num_classes, activation='sigmoid', name='fc1000')(output)\n",
    "    \n",
    "    model = keras.Model(\n",
    "        inputs=input_layer, \n",
    "        outputs=output\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "smooth-award",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_548 (Conv2D)             (None, 16, 16, 64)   9472        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_548 (BatchN (None, 16, 16, 64)   256         conv2d_548[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_548[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_0_maxpooling (MaxPooling (None, 8, 8, 64)     0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)         (None, 8, 8, 64)     36928       stage2_0_maxpooling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_short (Conv2D)         (None, 8, 8, 64)     4160        stage2_0_maxpooling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_add (Add)              (None, 8, 8, 64)     0           activation_25[0][0]              \n",
      "                                                                 stage2_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 64)     0           stage2_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)         (None, 8, 8, 64)     36928       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn3 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_add (Add)              (None, 8, 8, 64)     0           activation_28[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 8, 8, 64)     0           stage2_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)         (None, 8, 8, 64)     36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn5 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn6 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_add (Add)              (None, 8, 8, 64)     0           activation_31[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 8, 8, 64)     0           stage2_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv1 (Conv2D)         (None, 4, 4, 128)    73856       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 128)    0           stage3_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_short (Conv2D)         (None, 4, 4, 128)    8320        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 128)    0           stage3_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn4 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_add (Add)              (None, 4, 4, 128)    0           activation_34[0][0]              \n",
      "                                                                 stage3_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 128)    0           stage3_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn3 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 4, 128)    0           stage3_2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn4 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 4, 128)    0           stage3_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_add (Add)              (None, 4, 4, 128)    0           activation_37[0][0]              \n",
      "                                                                 activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 4, 4, 128)    0           stage3_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn5 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 4, 4, 128)    0           stage3_3_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn6 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 4, 4, 128)    0           stage3_3_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_add (Add)              (None, 4, 4, 128)    0           activation_40[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 4, 4, 128)    0           stage3_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv1 (Conv2D)         (None, 4, 4, 128)    147584      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn7 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 4, 4, 128)    0           stage3_4_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn8 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 4, 4, 128)    0           stage3_4_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_add (Add)              (None, 4, 4, 128)    0           activation_43[0][0]              \n",
      "                                                                 activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 4, 4, 128)    0           stage3_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv1 (Conv2D)         (None, 2, 2, 256)    295168      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 256)    0           stage4_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_short (Conv2D)         (None, 2, 2, 256)    33024       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 256)    0           stage4_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn4 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_add (Add)              (None, 2, 2, 256)    0           activation_46[0][0]              \n",
      "                                                                 stage4_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 256)    0           stage4_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn3 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 256)    0           stage4_2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn4 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 256)    0           stage4_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_add (Add)              (None, 2, 2, 256)    0           activation_49[0][0]              \n",
      "                                                                 activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 2, 2, 256)    0           stage4_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn5 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 2, 2, 256)    0           stage4_3_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn6 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 2, 2, 256)    0           stage4_3_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_add (Add)              (None, 2, 2, 256)    0           activation_52[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 2, 2, 256)    0           stage4_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn7 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 2, 2, 256)    0           stage4_4_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn8 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2, 2, 256)    0           stage4_4_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_add (Add)              (None, 2, 2, 256)    0           activation_55[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 2, 2, 256)    0           stage4_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn9 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 2, 2, 256)    0           stage4_5_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn10 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 2, 2, 256)    0           stage4_5_bn10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_add (Add)              (None, 2, 2, 256)    0           activation_58[0][0]              \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 2, 2, 256)    0           stage4_5_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv1 (Conv2D)         (None, 2, 2, 256)    590080      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn11 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_6_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 2, 2, 256)    0           stage4_6_bn11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn12 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_6_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 2, 2, 256)    0           stage4_6_bn12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_add (Add)              (None, 2, 2, 256)    0           activation_61[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 2, 2, 256)    0           stage4_6_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv1 (Conv2D)         (None, 1, 1, 512)    1180160     activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn1 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 1, 1, 512)    0           stage5_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn2 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_short (Conv2D)         (None, 1, 1, 512)    131584      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1, 1, 512)    0           stage5_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn4 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_add (Add)              (None, 1, 1, 512)    0           activation_64[0][0]              \n",
      "                                                                 stage5_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1, 1, 512)    0           stage5_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv1 (Conv2D)         (None, 1, 1, 512)    2359808     activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn3 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1, 1, 512)    0           stage5_2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn4 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 1, 1, 512)    0           stage5_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_add (Add)              (None, 1, 1, 512)    0           activation_67[0][0]              \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 1, 1, 512)    0           stage5_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv1 (Conv2D)         (None, 1, 1, 512)    2359808     activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn5 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 1, 1, 512)    0           stage5_3_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn6 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 1, 1, 512)    0           stage5_3_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_add (Add)              (None, 1, 1, 512)    0           activation_70[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 1, 1, 512)    0           stage5_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 512)    0           activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 10)           5130        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,319,754\n",
      "Trainable params: 21,302,602\n",
      "Non-trainable params: 17,152\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 기본값을 그대로 사용해서 ResNet-34모델을 building한다.\n",
    "resnet_34 = build_resnet()\n",
    "\n",
    "resnet_34.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-hawaii",
   "metadata": {},
   "source": [
    "## ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unsigned-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer (InputLayer)        [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_549 (Conv2D)             (None, 16, 16, 64)   9472        input_layer[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_549 (BatchN (None, 16, 16, 64)   256         conv2d_549[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 64)   0           batch_normalization_549[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "stage2_0_maxpooling (MaxPooling (None, 8, 8, 64)     0           activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv1 (Conv2D)         (None, 8, 8, 64)     4160        stage2_0_maxpooling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn1 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn2 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 64)     0           stage2_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn3 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_short (Conv2D)         (None, 8, 8, 256)    16640       stage2_0_maxpooling[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 256)    0           stage2_1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_bn4 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage2_1_add (Add)              (None, 8, 8, 256)    0           activation_75[0][0]              \n",
      "                                                                 stage2_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 256)    0           stage2_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv1 (Conv2D)         (None, 8, 8, 64)     16448       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn4 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn5 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 64)     0           stage2_2_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_bn6 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 256)    0           stage2_2_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_2_add (Add)              (None, 8, 8, 256)    0           activation_79[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 256)    0           stage2_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv1 (Conv2D)         (None, 8, 8, 64)     16448       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn7 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv2 (Conv2D)         (None, 8, 8, 64)     36928       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn8 (BatchNormalizatio (None, 8, 8, 64)     256         stage2_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 64)     0           stage2_3_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_conv3 (Conv2D)         (None, 8, 8, 256)    16640       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_bn9 (BatchNormalizatio (None, 8, 8, 256)    1024        stage2_3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 256)    0           stage2_3_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage2_3_add (Add)              (None, 8, 8, 256)    0           activation_83[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 256)    0           stage2_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv1 (Conv2D)         (None, 4, 4, 128)    32896       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn1 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 4, 4, 128)    0           stage3_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn2 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 4, 4, 128)    0           stage3_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_conv3 (Conv2D)         (None, 4, 4, 512)    66048       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn3 (BatchNormalizatio (None, 4, 4, 512)    2048        stage3_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_short (Conv2D)         (None, 4, 4, 512)    131584      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 4, 4, 512)    0           stage3_1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_bn4 (BatchNormalizatio (None, 4, 4, 512)    2048        stage3_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage3_1_add (Add)              (None, 4, 4, 512)    0           activation_87[0][0]              \n",
      "                                                                 stage3_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 512)    0           stage3_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv1 (Conv2D)         (None, 4, 4, 128)    65664       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn4 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 128)    0           stage3_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn5 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 128)    0           stage3_2_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_conv3 (Conv2D)         (None, 4, 4, 512)    66048       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_bn6 (BatchNormalizatio (None, 4, 4, 512)    2048        stage3_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 512)    0           stage3_2_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_2_add (Add)              (None, 4, 4, 512)    0           activation_91[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 512)    0           stage3_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv1 (Conv2D)         (None, 4, 4, 128)    65664       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn7 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 128)    0           stage3_3_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn8 (BatchNormalizatio (None, 4, 4, 128)    512         stage3_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 128)    0           stage3_3_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_conv3 (Conv2D)         (None, 4, 4, 512)    66048       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_bn9 (BatchNormalizatio (None, 4, 4, 512)    2048        stage3_3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 512)    0           stage3_3_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_3_add (Add)              (None, 4, 4, 512)    0           activation_95[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 512)    0           stage3_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv1 (Conv2D)         (None, 4, 4, 128)    65664       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn10 (BatchNormalizati (None, 4, 4, 128)    512         stage3_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 128)    0           stage3_4_bn10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv2 (Conv2D)         (None, 4, 4, 128)    147584      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn11 (BatchNormalizati (None, 4, 4, 128)    512         stage3_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 128)    0           stage3_4_bn11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_conv3 (Conv2D)         (None, 4, 4, 512)    66048       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_bn12 (BatchNormalizati (None, 4, 4, 512)    2048        stage3_4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 512)    0           stage3_4_bn12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage3_4_add (Add)              (None, 4, 4, 512)    0           activation_99[0][0]              \n",
      "                                                                 activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 512)    0           stage3_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv1 (Conv2D)         (None, 2, 2, 256)    131328      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn1 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 2, 2, 256)    0           stage4_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn2 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 2, 2, 256)    0           stage4_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn3 (BatchNormalizatio (None, 2, 2, 1024)   4096        stage4_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_short (Conv2D)         (None, 2, 2, 1024)   525312      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 2, 2, 1024)   0           stage4_1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_bn4 (BatchNormalizatio (None, 2, 2, 1024)   4096        stage4_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_1_add (Add)              (None, 2, 2, 1024)   0           activation_103[0][0]             \n",
      "                                                                 stage4_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 2, 2, 1024)   0           stage4_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv1 (Conv2D)         (None, 2, 2, 256)    262400      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn4 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 2, 2, 256)    0           stage4_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn5 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 2, 2, 256)    0           stage4_2_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_bn6 (BatchNormalizatio (None, 2, 2, 1024)   4096        stage4_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 2, 2, 1024)   0           stage4_2_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_2_add (Add)              (None, 2, 2, 1024)   0           activation_107[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 2, 2, 1024)   0           stage4_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv1 (Conv2D)         (None, 2, 2, 256)    262400      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn7 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 2, 2, 256)    0           stage4_3_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn8 (BatchNormalizatio (None, 2, 2, 256)    1024        stage4_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 2, 2, 256)    0           stage4_3_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_bn9 (BatchNormalizatio (None, 2, 2, 1024)   4096        stage4_3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 2, 2, 1024)   0           stage4_3_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_3_add (Add)              (None, 2, 2, 1024)   0           activation_111[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 2, 2, 1024)   0           stage4_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv1 (Conv2D)         (None, 2, 2, 256)    262400      activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn10 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 2, 2, 256)    0           stage4_4_bn10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn11 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 2, 2, 256)    0           stage4_4_bn11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_bn12 (BatchNormalizati (None, 2, 2, 1024)   4096        stage4_4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 2, 2, 1024)   0           stage4_4_bn12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_4_add (Add)              (None, 2, 2, 1024)   0           activation_115[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 2, 2, 1024)   0           stage4_4_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv1 (Conv2D)         (None, 2, 2, 256)    262400      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn13 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 2, 2, 256)    0           stage4_5_bn13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn14 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 2, 2, 256)    0           stage4_5_bn14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_bn15 (BatchNormalizati (None, 2, 2, 1024)   4096        stage4_5_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 2, 2, 1024)   0           stage4_5_bn15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_5_add (Add)              (None, 2, 2, 1024)   0           activation_119[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 2, 2, 1024)   0           stage4_5_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv1 (Conv2D)         (None, 2, 2, 256)    262400      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn16 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_6_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 2, 2, 256)    0           stage4_6_bn16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv2 (Conv2D)         (None, 2, 2, 256)    590080      activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn17 (BatchNormalizati (None, 2, 2, 256)    1024        stage4_6_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 2, 2, 256)    0           stage4_6_bn17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_conv3 (Conv2D)         (None, 2, 2, 1024)   263168      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_bn18 (BatchNormalizati (None, 2, 2, 1024)   4096        stage4_6_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 2, 2, 1024)   0           stage4_6_bn18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "stage4_6_add (Add)              (None, 2, 2, 1024)   0           activation_123[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 2, 2, 1024)   0           stage4_6_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv1 (Conv2D)         (None, 1, 1, 512)    524800      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn1 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 1, 1, 512)    0           stage5_1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn2 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 1, 1, 512)    0           stage5_1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_conv3 (Conv2D)         (None, 1, 1, 2048)   1050624     activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn3 (BatchNormalizatio (None, 1, 1, 2048)   8192        stage5_1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_short (Conv2D)         (None, 1, 1, 2048)   2099200     activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 1, 1, 2048)   0           stage5_1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_bn4 (BatchNormalizatio (None, 1, 1, 2048)   8192        stage5_1_short[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_1_add (Add)              (None, 1, 1, 2048)   0           activation_127[0][0]             \n",
      "                                                                 stage5_1_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 1, 1, 2048)   0           stage5_1_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv1 (Conv2D)         (None, 1, 1, 512)    1049088     activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn4 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 1, 1, 512)    0           stage5_2_bn4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn5 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 1, 1, 512)    0           stage5_2_bn5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_conv3 (Conv2D)         (None, 1, 1, 2048)   1050624     activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_bn6 (BatchNormalizatio (None, 1, 1, 2048)   8192        stage5_2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 1, 1, 2048)   0           stage5_2_bn6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_2_add (Add)              (None, 1, 1, 2048)   0           activation_131[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 1, 1, 2048)   0           stage5_2_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv1 (Conv2D)         (None, 1, 1, 512)    1049088     activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn7 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 1, 1, 512)    0           stage5_3_bn7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv2 (Conv2D)         (None, 1, 1, 512)    2359808     activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn8 (BatchNormalizatio (None, 1, 1, 512)    2048        stage5_3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 1, 1, 512)    0           stage5_3_bn8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_conv3 (Conv2D)         (None, 1, 1, 2048)   1050624     activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_bn9 (BatchNormalizatio (None, 1, 1, 2048)   8192        stage5_3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 1, 1, 2048)   0           stage5_3_bn9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stage5_3_add (Add)              (None, 1, 1, 2048)   0           activation_135[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 1, 1, 2048)   0           stage5_3_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 10)           20490       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원하는 블록의 설계에 따라 매개변수로 리스트를 전달해 줍니다.\n",
    "resnet_50 = build_resnet(\n",
    "    num_cnn_list=[3, 4, 6, 3],\n",
    "    channel_list=[64,128,256,512],\n",
    "    is_50=True, \n",
    ")\n",
    "\n",
    "resnet_50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-culture",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "- 기본적으로 논문을 다 읽어보고 모델 구현을 시도 했지만, 너무 어려운 과정이었고, 많이 물어보며 진행을 했다.\n",
    "- 많은 블로그와 유튜브에 ResNet50에 관한 내용은 많아서 찾기 쉬웠지만, ResNet34는 50에서 많은 변형을 하느라 파라미터의 갯수를 맞추는게 쉽지 않았다.\n",
    "- 파이토치로 구현된 것이 많았기에 이 또한 공부하는데 시간이 많이 걸렸고, 끝까지 혼자 제대로 된 모델을 구현하는데 실패했다.\n",
    "- Layer 층을 구성하는데 어떤 것이 필수적으로 있어야하는지는 알겠지만, 현재 뭐가 부족한지 다른 코드들과 비교를 해 봐도 정확히 알 수 없어, 끝난 후에 다시 제대로 해볼 생각이다.\n",
    "- 34와 50의 다른 점을 확실히 알게 되었고, 재미도 있었기에 계속해서 시도해 보겠다.\n",
    "    - 현재 부족한 점은 파이썬 공부가 절실하다...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
